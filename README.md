## Tech Challenge #3 **ğŸ§©**

ğŸ¯Objetivo: PrevisÃ£o de popularidade de mÃºsicas do Spotify via classificaÃ§Ã£o binÃ¡ria (popular vs. nÃ£o-popular).

### **Tecnologias utilizadas ğŸ’¡**

NÃ³s utilizamos 4 containers em Docker para isolamento dos ambientes:
* app-ui: aplicaÃ§Ã£o web streamlit que roda o modelo
* api-data: API de ingestÃ£o dos dados (CSV -> Postgres)
* app-database: host do banco de dados Postgres SQL
* jupyter: servidor com jupyter notebook para treinamento do modelo.

A imagem abaixo traz a visÃ£o dos containers de forma mais detalhada.
<!-- ![containers](docs/containers.png) -->
<img src="docs/containers.png" alt="containers" width="500"/>

A arquitetura da nossa soluÃ§Ã£o pode ser vista na imagem abaixo.
<!-- ![architeture](docs/architeture.png) -->
<img src="docs/architeture.png" alt="architeture" width="800"/>

Nela, verificamos que os dados, originalmente do Kaggle, sÃ£o salvos no formato csv localmente. EntÃ£o, a API de ingestÃ£o de dados faz o carregamento desses dados para o Banco de Dados Postgres SQL. 

Os dados armazenados no Postgres DB sÃ£o lidos dentro do Jupyter Notebook, e entÃ£o utilizados para todas as etapas de construÃ§Ã£o do modelo, desde a anÃ¡lise exploratÃ³ria dos dados, atÃ© o treinamento e validaÃ§Ã£o. Como resultado, o modelo campeÃ£o Ã© salvo como um artefato (pickle). 

O artefato de modelo Ã© carregado pela aplicaÃ§Ã£o web em streamlit, que farÃ¡ o consumo do modelo a partir de dados de entrada inseridos pelo usuÃ¡rio.

---

### Estrutura de pastas **ğŸ“‚**

---

* **app**: Armazena os arquivos relativos Ã  aplicaÃ§Ã£o (streamlit)
* **docker**: ContÃ©m todos os dockerfiles responsÃ¡veis pela criaÃ§Ã£o de cada um dos containers
* **docs**: ContÃ©m diagramas, imagens e demais arquivos para documentaÃ§Ã£o
* **src**: Possui os dados brutos no formato CSV e os mÃ³dulos de interface com o banco de dados (Postgres) para o carregamento dos dados
* **training_model**: Possui todos os jupyter notebooks utilizados para as anÃ¡lises, treinamento e validaÃ§Ã£o do modelo. O notebook principal, que serve tambÃ©m como documentaÃ§Ã£o base, Ã© o `training_model.ipynb` na raiz deste diretÃ³rio.


```
tech_challenge_3
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docker
â”‚   â”œâ”€â”€ fastapi
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ jupyter
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ streamlit
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ architeture.png
â”‚   â”œâ”€â”€ containers.png
â”‚   â”œâ”€â”€ DesignOfExperiments.drawio
â”‚   â””â”€â”€ infra_tech3.drawio
â”œâ”€â”€ README.md
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â””â”€â”€ spotify_raw_dataset.csv
â”‚   â”œâ”€â”€ interfaces
â”‚   â”‚   â”œâ”€â”€ db_definitions.py
â”‚   â”‚   â”œâ”€â”€ db_interfaces.py
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”‚   â”œâ”€â”€ db_definitions.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ db_interfaces.cpython-312.pyc
â”‚   â”‚   â”‚   â””â”€â”€ __init__.cpython-312.pyc
â”‚   â”‚   â””â”€â”€ test_db_interfaces.py
â”‚   â”œâ”€â”€ mainlog.log
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â””â”€â”€ main.cpython-312.pyc
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ training_model
    â”œâ”€â”€ chrys
    â”‚   â””â”€â”€ training_model_spotify.ipynb
    â”œâ”€â”€ interfaces
    â”œâ”€â”€ raiane
    â”‚   â”œâ”€â”€ training_model_spotify.ipynb
    â”‚   â””â”€â”€ training_model_spotify_v2.ipynb
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ test_connect_db.ipynb
    â””â”€â”€ training_model.ipynb
```

### InÃ­cio rÃ¡pido ğŸš€

---

1. Certifique-se de que vocÃª possui uma instalaÃ§Ã£o Docker funcionando.
2. VÃ¡ na raiz do projeto (ou seja, na raÃ­z de `tech_challenge_3`) e rode o comando `docker compose up --build -d`. A criaÃ§Ã£o dos containers demora em torno de 5 minutos, mas pode variar dependendo das configuraÃ§Ãµes do seu computador.
3. Certifique-se de que os containers estÃ£o com state `running`.
4. Certifique-se que vocÃª tem os endereÃ§os e portas de rede mapeadas para o uso da chamada via `localhost`.
5. FaÃ§a um teste, acessando o Swagger API de Carregamento dos Dados no endereÃ§o `http://localhost/8000/docs`. Aqui, vocÃª pode testar a conexÃ£o com o Database Postgres tambÃ©m. VocÃª tambÃ©m pode acessar o Jupyter Server no endereÃ§o `http://localhost/8888/`, caso deseje.
6. Acesse a aplicaÃ§Ã£o no endereÃ§o `http://localhost/8501/`. Insira os dados desejados da sua mÃºsica e verifique a prediÃ§Ã£o de popularidade dela.

### Demos âš’ï¸

---

Clique [aqui](colocar link do drive) e assita a demo.
